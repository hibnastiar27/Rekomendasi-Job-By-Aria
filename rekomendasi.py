# -*- coding: utf-8 -*-
"""Rekomendasi2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12topbeMuzODRQGN-TEoYBjmyjb1KP9ts

# Import
"""

pip install kagglehub[pandas-datasets]

# Dasar
import kagglehub
from kagglehub import KaggleDatasetAdapter
import pandas as pd
import re

# Modling Dan Evaluasi
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

"""# Load Data"""

# Set the path to the file you'd like to load
file_path = "job_descriptions.csv"

# Load the latest version
df = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "ravindrasinghrana/job-description-dataset",
  file_path,
  # Provide any additional arguments like
  # sql_query or pandas_kwargs. See the
  # documenation for more information:
  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas
)

"""# EDA

Jumlah Keseluruhan Data
"""

df.info()

"""Fitur yang akan diolah

1. Job Title
2. Job Description
3. skills
4. Responsibilities
5. Qualifications
6. location
7. Work Type

Kolom Unik
"""

len(df['Job Title'].unique())

len(df['skills'].unique())

print(df['Qualifications'].unique()) # Pendidikan
print(len(df['Qualifications'].unique()))

# print(df['Responsibilities'].unique()) # Pengalaman
print(len(df['Responsibilities'].unique()))

print(df['location'].unique()) # Lokasi
print(len(df['location'].unique()))

print(df['Work Type'].unique()) # Jenis Pekerjaan
print(len(df['Work Type'].unique()))

"""## Summary

1. Total data ada 1juta lebih, tetapi yang akan digunakan hanya sample yaitu 10 ribu saja.
2. yang akan digunakan ada 7 yaitu :
  1. Job Title
  2. Job Description
  3. skills
  4. Responsibilities
  5. Qualifications
  6. location
  7. Work Type

# Cleaning

- Filter hanya 7 fitur seperti yang di EDA
- Hilangkan Null Jika ada
- Hilangkan Duplikat jika ada
- Buat jadi sample 10k data

Sampling dulu jadi 10k data
"""

df_sample = df.sample(n=10000, random_state=27)
df_sample.info()

"""7 Fitur"""

df_clean = df_sample.copy()

df_clean = df_clean[['Job Title', 'Job Description', 'skills', 'Responsibilities', 'Qualifications', 'location', 'Work Type']]

df_clean.info()

"""Hapus Duplikat"""

df_clean.duplicated().sum()

df_clean = df_clean.drop_duplicates()
df_clean.duplicated().sum()

df_clean.info()

"""Jika Null Hapus"""

df_clean.isnull().sum()

"""## Sumary

1. 7 Fitur yang digunakan
2. Terdapat Duplicate sebanyak (19) dan dihapus
3. tidak ada data yang null
"""

df_clean.head()

"""# Modeling"""

df_modeling = df_clean.copy()

"""## Data  Preprosessing"""

df_modeling = df_modeling.reset_index(drop=True)

df_modeling['combined_text'] = (
  df_modeling['skills'] + ' ' +
  df_modeling['Job Description'] + ' ' +
  df_modeling['Responsibilities'] + ' ' +
  df_modeling['Qualifications'] + ' ' +
  df_modeling['location'] + ' ' +
  df_modeling['Work Type']
)

def clean_text(text):
  text = text.lower()
  text = re.sub(r'\d+', '', text)  # hapus angka
  text = re.sub(r'[^\w\s]', '', text)  # hapus tanda baca
  return text

df_modeling['combined_text'] = df_modeling['combined_text'].apply(clean_text)

"""Ingin prediksi `Work Type`"""

label_encoder = LabelEncoder()
df_modeling['Work Type Encoded'] = label_encoder.fit_transform(df_modeling['Work Type'])

"""## Content Based Filtering"""

# TF-IDF Vectirization
tfidf = TfidfVectorizer(stop_words='english', max_features=10000)
tfidf_matrix = tfidf.fit_transform(df_modeling['combined_text'])

# Cosine Similarty
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Lowercase untuk pencarian job title
df_modeling['Job Title Lower'] = df_modeling['Job Title'].str.lower()

# Mapping index berdasarkan job title lowercase
indices = pd.Series(df_modeling.index, index=df_modeling['Job Title Lower']).drop_duplicates()

# Fungsi Rekomendasi
# indices = pd.Series(df_modeling.index, index=df_modeling['Job Title']).drop_duplicates()
def recommend_jobs(job_title, top_n=5):
  # Cari job title yang mengandung kata kunci, dalam df_modeling
  matches = df_modeling[df_modeling['Job Title'].str.lower().str.contains(job_title.lower())]

  if matches.empty:
    return "Job Title tidak ditemukan."

  # Ambil index posisi (0â€“9999) dari hasil match (bukan index asli dari dataset awal)
  idx = matches.index[0]

  # Hitung similarity terhadap semua job
  sim_scores = list(enumerate(cosine_sim[idx]))
  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

  # Ambil top_n, skip dirinya sendiri (index ke-0)
  sim_scores = sim_scores[1:top_n+1]
  job_indices = [i[0] for i in sim_scores]
  scores = [round(score * 100, 2) for _, score in sim_scores]

  # Ambil data dari df_modeling
  result = df_modeling.iloc[job_indices][['Job Title', 'location', 'Work Type']].copy()
  result['Similarity (%)'] = scores

  return result

df_modeling = df_modeling.reset_index(drop=True)

recommend_jobs('Software Engine')

"""## Klasifikasi Work Type Berdasarkan Konten"""

# Train Test Split
X = df_modeling['combined_text']
y = df_modeling['Work Type Encoded']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)

# Pipline Model
clf_pipeline = Pipeline([
  ('tfidf', TfidfVectorizer(stop_words='english', max_features=10000)),
  ('clf', RandomForestClassifier(n_estimators=50, random_state=27))
])

clf_pipeline.fit(X_train, y_train)

"""# Evaluation"""

y_pred = clf_pipeline.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred, target_names=label_encoder.classes_))

"""Accuracy nya 99,85 -> pembulatan

# Summary Modeling Dan Evaluasi

#### 1. **Preprocessing dan Feature Engineering**

* Menggabungkan kolom teks utama (`Job Title`, `Job Description`, `skills`, `Responsibilities`, `Qualifications`) menjadi satu kolom `combined_text`.
* Menggunakan TF-IDF Vectorizer dengan `max_features=10000` dan stopwords bahasa Inggris untuk representasi teks.

#### 2. **Content-Based Job Recommendation**

* Menghitung cosine similarity antar job berdasarkan `combined_text`.
* Fungsi rekomendasi menerima input `Job Title`, mencari posisi job tersebut dalam dataset, lalu merekomendasikan job dengan similarity tertinggi.
* Contoh hasil rekomendasi untuk **"Software Engineer"** menunjukkan job-job dengan `Job Title` sama dari lokasi dan tipe kerja berbeda dengan similarity > 97%, menandakan rekomendasi relevan dan spesifik.

| Job Title         | Location | Work Type | Similarity (%) |
| ----------------- | -------- | --------- | -------------- |
| Software Engineer | Belgrade | Intern    | 97.77          |
| Software Engineer | Harare   | Contract  | 97.68          |
| Software Engineer | Ankara   | Temporary | 97.63          |
| Software Engineer | Belgrade | Part-Time | 97.57          |
| Software Engineer | Prague   | Part-Time | 97.56          |

---

#### 3. **Work Type Classification**

* Target: kolom `Work Type` yang sudah diencoding (`Work Type Encoded`).
* Data dibagi train-test dengan perbandingan 80:20.
* Pipeline model menggunakan:

  * TF-IDF Vectorizer (stop\_words='english', max\_features=10000)
  * Random Forest Classifier (50 estimator, random\_state=27)
* Model berhasil mencapai **akurasi sangat tinggi 99.85%** pada data testing.

##### Metrics Classification Report (Test Set)

| Class     | Precision | Recall | F1-score | Support |
| --------- | --------- | ------ | -------- | ------- |
| Contract  | 1.00      | 1.00   | 1.00     | 432     |
| Full-Time | 0.99      | 1.00   | 1.00     | 398     |
| Intern    | 1.00      | 1.00   | 1.00     | 409     |
| Part-Time | 1.00      | 1.00   | 1.00     | 365     |
| Temporary | 1.00      | 1.00   | 1.00     | 393     |

* **Overall Accuracy:** 99.85%
* Model menunjukkan performa sangat baik untuk klasifikasi jenis pekerjaan berdasarkan teks deskriptif.

---

### **Kesimpulan:**

* **Content-Based Filtering** dengan TF-IDF dan cosine similarity efektif memberikan rekomendasi pekerjaan yang sangat relevan berdasarkan kemiripan deskripsi pekerjaan.
* **Random Forest dengan TF-IDF** mampu mengklasifikasi tipe pekerjaan (`Work Type`) dengan akurasi hampir sempurna, menandakan fitur teks sudah sangat representatif.
* Kombinasi kedua metode ini bisa diaplikasikan untuk sistem rekomendasi karir sekaligus prediksi jenis kontrak kerja dari deskripsi job posting.

---

Kalau kamu mau, aku bisa bantu buat visualisasi evaluasi, tuning model, atau menambah fitur lain untuk improve sistemnya!
"""